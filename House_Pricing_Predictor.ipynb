{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "House Pricing Predictor",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "U1OL4iaVyAuD",
        "y6N18svrw-mr",
        "y2XJLSdQy5Xs",
        "_H8Ik2_Xzhla"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/morarsebastianroloway/HousePricingPredictor/blob/master/House_Pricing_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "U1OL4iaVyAuD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Description"
      ]
    },
    {
      "metadata": {
        "id": "frLJr63puxx6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this simple example, we will train a model to predict housing prices. Our training data consists of 14 variables. 13 variables are predictor variables, with the last being the target variable. Our training data comes from the Boston Housing Price Prediction dataset, which is hosted by Kaggle.\n",
        "\n",
        "Data description\n",
        "The Boston data frame has 506 rows and 14 columns.\n",
        "\n",
        "This data frame contains the following columns:\n",
        "\n",
        "    crim\n",
        "    - per capita crime rate by town.\n",
        "\n",
        "    zn\n",
        "    - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "\n",
        "    indus\n",
        "    - proportion of non-retail business acres per town.\n",
        "\n",
        "    chas\n",
        "     - Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
        "\n",
        "    nox\n",
        "    - nitrogen oxides concentration (parts per 10 million).\n",
        "\n",
        "    rm\n",
        "    - average number of rooms per dwelling.\n",
        "\n",
        "    age\n",
        "    - proportion of owner-occupied units built prior to 1940.\n",
        "\n",
        "    dis\n",
        "    - weighted mean of distances to five Boston employment centres.\n",
        "\n",
        "    rad\n",
        "    - index of accessibility to radial highways.\n",
        "\n",
        "    tax\n",
        "    - full-value property-tax rate per $10,000.\n",
        "    \n",
        "    ptratio\n",
        "    - pupil-teacher ratio by town.\n",
        "\n",
        "    black\n",
        "    - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.\n",
        "\n",
        "    lstat\n",
        "    - lower status of the population (percent).\n",
        "\n",
        "    medv\n",
        "    - median value of owner-occupied homes in $1000s.\n",
        "\n",
        "Source\n",
        "Harrison, D. and Rubinfeld, D.L. (1978) Hedonic prices and the demand for clean air. J. Environ. Economics and Management 5, 81–102.\n",
        "\n",
        "Belsley D.A., Kuh, E. and Welsch, R.E. (1980) Regression Diagnostics. Identifying Influential Data and Sources of Collinearity. New York: Wiley. "
      ]
    },
    {
      "metadata": {
        "id": "y6N18svrw-mr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Import what we need and download train data\n",
        "We will need to download train.csv and store it somewhere accessible. Let’s start by importing what we need and reading in our data."
      ]
    },
    {
      "metadata": {
        "id": "69vxCTEBt4jC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QjtxNU0Lv-3k",
        "colab_type": "code",
        "outputId": "84686abc-eb59-48a8-fff9-74aa25352114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "cell_type": "code",
      "source": [
        "#read training data\n",
        "train_df = pd.read_csv('https://firebasestorage.googleapis.com/v0/b/bible-project-2365c.appspot.com/o/train.csv?alt=media&token=9c5d17c2-0589-43ea-b992-e7c2ad02d714', index_col='ID')\n",
        "train_df.head()\n",
        "\n",
        "# The above code will print the first five rows of the imported data. We will\n",
        "# see the column names printed along with the data in a tabular format. Our \n",
        "# target variable is called medv, so we store it."
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crim</th>\n",
              "      <th>zn</th>\n",
              "      <th>indus</th>\n",
              "      <th>chas</th>\n",
              "      <th>nox</th>\n",
              "      <th>rm</th>\n",
              "      <th>age</th>\n",
              "      <th>dis</th>\n",
              "      <th>rad</th>\n",
              "      <th>tax</th>\n",
              "      <th>ptratio</th>\n",
              "      <th>black</th>\n",
              "      <th>lstat</th>\n",
              "      <th>medv</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.08829</td>\n",
              "      <td>12.5</td>\n",
              "      <td>7.87</td>\n",
              "      <td>0</td>\n",
              "      <td>0.524</td>\n",
              "      <td>6.012</td>\n",
              "      <td>66.6</td>\n",
              "      <td>5.5605</td>\n",
              "      <td>5</td>\n",
              "      <td>311</td>\n",
              "      <td>15.2</td>\n",
              "      <td>395.60</td>\n",
              "      <td>12.43</td>\n",
              "      <td>22.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
              "ID                                                                              \n",
              "1   0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
              "2   0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
              "4   0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
              "5   0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
              "7   0.08829  12.5   7.87     0  0.524  6.012  66.6  5.5605    5  311     15.2   \n",
              "\n",
              "     black  lstat  medv  \n",
              "ID                       \n",
              "1   396.90   4.98  24.0  \n",
              "2   396.90   9.14  21.6  \n",
              "4   394.63   2.94  33.4  \n",
              "5   396.90   5.33  36.2  \n",
              "7   395.60  12.43  22.9  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "metadata": {
        "id": "dldBwtldy0Ra",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictors = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad',\n",
        "              'tax', 'ptratio', 'black', 'lstat']\n",
        "target = 'medv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y2XJLSdQy5Xs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Normalize data for neural networks to perform optimally"
      ]
    },
    {
      "metadata": {
        "id": "S0_63X6_wboz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ta2xZveVzDQ1",
        "colab_type": "code",
        "outputId": "51f6038a-7395-4583-adec-6c10841e651c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "# If you take a look at the data, you will see that the different columns have \n",
        "# different ranges. This is not good for gradient descent. We need to have the \n",
        "# columns range between 0 and 1\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "# Scale both the training inputs and outputs\n",
        "scaled_train = scaler.fit_transform(train_df)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
            "  return self.partial_fit(X, y)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "BU59APvizTjC",
        "colab_type": "code",
        "outputId": "aff315e9-2609-4520-f4c7-191f56e715ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# Print out the adjustment that the scaler applied to the total_earnings column \n",
        "# of data\n",
        "print(\"Note: median values were scaled by multiplying by {:.10f} and adding {:.6f}\".format(scaler.scale_[13], scaler.min_[13]))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Note: median values were scaled by multiplying by 0.0222222222 and adding -0.111111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i-odj3c-zaSC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "multiplied_by = scaler.scale_[13]\n",
        "added = scaler.min_[13]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZTF6xFOuzcUy",
        "colab_type": "code",
        "outputId": "cbb11d12-d8e1-4334-85c3-38c364f1c12c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(type(scaled_train))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FwGdKjs-zfc9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Scaling produces a Numpy Array. We need to create a DataFrame out of that. \n",
        "scaled_train_df = pd.DataFrame(scaled_train, columns=train_df.columns.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_H8Ik2_Xzhla",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Let't build our model\n"
      ]
    },
    {
      "metadata": {
        "id": "tVZd5EtUzm17",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We are now reading to start building our Neural Network. We will make use of \n",
        "# a Sequential model.\n",
        "model = tf.keras.Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Bx3IQxAzuvM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We can now add layers to our model. We will be creating fully connected\n",
        "# layers using model.add(). The first call creates two layers, while subsequent\n",
        "# calls add one layer each. We need to tell each layer what its output will be,\n",
        "# which is the number of neurons it will output. We also need to specify the \n",
        "# activation of the layers. In this case, we use the relu activation function.\n",
        "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "# Notice that the final layer outputs one value. That is because we are\n",
        "# predicting a continuous variable. For the same reason, we do not specify an\n",
        "# activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dg6IdG4X0dJd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Next, we need to compile our model. We do this by specifying our loss \n",
        "# function and our optimizer\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kn-EghfF0n3F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We are now ready to train our model. Before we do that, we need to get our\n",
        "# training dataset ready. We will leave out the first ten rows of our data so\n",
        "# we can use them for validation. We will separate our predictors into X, and\n",
        "# our target into Y.\n",
        "X = scaled_train_df.drop(target, axis=1).values\n",
        "Y = scaled_train_df[[target]].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cjwYvs8x00w-",
        "colab_type": "code",
        "outputId": "1973c8b0-fc2b-4df0-9643-228979fc7f84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1791
        }
      },
      "cell_type": "code",
      "source": [
        "# We will train our model by passing in our training dataset. We also need to\n",
        "# specify the number of times we would like to go over our training data. This\n",
        "# is called an epoch.\n",
        "model.fit(\n",
        "    X[10:],\n",
        "    Y[10:],\n",
        "    epochs=50,\n",
        "    shuffle=True,\n",
        "    verbose=2\n",
        ")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " - 1s - loss: 0.1309\n",
            "Epoch 2/50\n",
            " - 0s - loss: 0.0504\n",
            "Epoch 3/50\n",
            " - 0s - loss: 0.0298\n",
            "Epoch 4/50\n",
            " - 0s - loss: 0.0233\n",
            "Epoch 5/50\n",
            " - 0s - loss: 0.0205\n",
            "Epoch 6/50\n",
            " - 0s - loss: 0.0170\n",
            "Epoch 7/50\n",
            " - 0s - loss: 0.0141\n",
            "Epoch 8/50\n",
            " - 0s - loss: 0.0121\n",
            "Epoch 9/50\n",
            " - 0s - loss: 0.0108\n",
            "Epoch 10/50\n",
            " - 0s - loss: 0.0100\n",
            "Epoch 11/50\n",
            " - 0s - loss: 0.0143\n",
            "Epoch 12/50\n",
            " - 0s - loss: 0.0107\n",
            "Epoch 13/50\n",
            " - 0s - loss: 0.0095\n",
            "Epoch 14/50\n",
            " - 0s - loss: 0.0082\n",
            "Epoch 15/50\n",
            " - 0s - loss: 0.0072\n",
            "Epoch 16/50\n",
            " - 0s - loss: 0.0072\n",
            "Epoch 17/50\n",
            " - 0s - loss: 0.0069\n",
            "Epoch 18/50\n",
            " - 0s - loss: 0.0065\n",
            "Epoch 19/50\n",
            " - 0s - loss: 0.0057\n",
            "Epoch 20/50\n",
            " - 0s - loss: 0.0059\n",
            "Epoch 21/50\n",
            " - 0s - loss: 0.0056\n",
            "Epoch 22/50\n",
            " - 0s - loss: 0.0058\n",
            "Epoch 23/50\n",
            " - 0s - loss: 0.0059\n",
            "Epoch 24/50\n",
            " - 0s - loss: 0.0050\n",
            "Epoch 25/50\n",
            " - 0s - loss: 0.0051\n",
            "Epoch 26/50\n",
            " - 0s - loss: 0.0050\n",
            "Epoch 27/50\n",
            " - 0s - loss: 0.0044\n",
            "Epoch 28/50\n",
            " - 0s - loss: 0.0053\n",
            "Epoch 29/50\n",
            " - 0s - loss: 0.0046\n",
            "Epoch 30/50\n",
            " - 0s - loss: 0.0042\n",
            "Epoch 31/50\n",
            " - 0s - loss: 0.0046\n",
            "Epoch 32/50\n",
            " - 0s - loss: 0.0043\n",
            "Epoch 33/50\n",
            " - 0s - loss: 0.0040\n",
            "Epoch 34/50\n",
            " - 0s - loss: 0.0039\n",
            "Epoch 35/50\n",
            " - 0s - loss: 0.0050\n",
            "Epoch 36/50\n",
            " - 0s - loss: 0.0038\n",
            "Epoch 37/50\n",
            " - 0s - loss: 0.0041\n",
            "Epoch 38/50\n",
            " - 0s - loss: 0.0042\n",
            "Epoch 39/50\n",
            " - 0s - loss: 0.0043\n",
            "Epoch 40/50\n",
            " - 0s - loss: 0.0035\n",
            "Epoch 41/50\n",
            " - 0s - loss: 0.0042\n",
            "Epoch 42/50\n",
            " - 0s - loss: 0.0050\n",
            "Epoch 43/50\n",
            " - 0s - loss: 0.0039\n",
            "Epoch 44/50\n",
            " - 0s - loss: 0.0038\n",
            "Epoch 45/50\n",
            " - 0s - loss: 0.0033\n",
            "Epoch 46/50\n",
            " - 0s - loss: 0.0033\n",
            "Epoch 47/50\n",
            " - 0s - loss: 0.0038\n",
            "Epoch 48/50\n",
            " - 0s - loss: 0.0041\n",
            "Epoch 49/50\n",
            " - 0s - loss: 0.0036\n",
            "Epoch 50/50\n",
            " - 0s - loss: 0.0033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f422026fd68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "pzbeDZm91CL_",
        "colab_type": "code",
        "outputId": "184a66fc-d036-4f44-a2bf-2d9d1ddb4091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "test_error_rate = model.evaluate(X[:10], Y[:10], verbose=0)\n",
        "print(\"The mean squared error (MSE) for the test data set is: {}\".format(test_error_rate))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean squared error (MSE) for the test data set is: 0.0032902092207223177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lCBp9qrDaCA3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Make a prediction"
      ]
    },
    {
      "metadata": {
        "id": "H3UsvUPF1HNV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# At this point we are ready to make a prediction.\n",
        "prediction = model.predict(X[:1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mmUr9MgR1Me0",
        "colab_type": "code",
        "outputId": "e07c6f69-d2bb-4772-9ab8-c9f3e5f37935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "y_0 = prediction[0][0]\n",
        "print('Prediction with scaling - {}'.format(y_0))\n",
        "y_0 -= added\n",
        "y_0 /= multiplied_by\n",
        "print(\"Housing Price Prediction  - ${}\".format(y_0*1000))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction with scaling - 0.47554340958595276\n",
            "Housing Price Prediction  - $26399.453431367874\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}